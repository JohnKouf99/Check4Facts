{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')  \n",
    "from models import *\n",
    "from df_handling import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the datasets we want to test (you can change the dataframes you want to load accordingly)\n",
    "greek2 = pd.read_csv('../data/greek_par_emb.csv')\n",
    "greek2 = unravel_df(greek2, ['text_embedding_claim', 'text_embedding_par'])\n",
    "cyprus2 = pd.read_csv('../data/cyprus_par_emb.csv')\n",
    "cyprus2 = unravel_df(cyprus2, ['text_embedding_claim','text_embedding_par'])\n",
    "check4facts2 = pd.read_csv('../data/check4facts_par_emb.csv')\n",
    "check4facts2 = unravel_df(check4facts2, ['text_embedding_claim','text_embedding_par'])\n",
    "#aggregating the claim id for each dataset\n",
    "check4facts2['claim_id'] += int(greek2['claim_id'].iloc[-1]) +1\n",
    "cyprus2['claim_id'] += int(check4facts2['claim_id'].iloc[-1]) +1\n",
    "# #creating source labels for each dataset (optionally, not necessary for the classification)\n",
    "# temp_df = pd.read_csv('../data/greek_web_scraping.csv')\n",
    "# temp_df['source'] = temp_df['url'].apply(lambda x: 0 if \"ellinikahoaxes\" in x else (1 if \"factcheckgreek\" in x else None))\n",
    "# greek1 = pd.merge(greek1, temp_df[['id','source', 'claim']], on='claim', how='inner')\n",
    "# cyprus1['source'] = 3\n",
    "# check4facts1['source'] = 2\n",
    "\n",
    "#finally we create the dataframe that the model will be trained on (you can also change this accordingly)\n",
    "df_train = pd.concat([greek2,cyprus2,check4facts2], ignore_index=True)\n",
    "df_train = df_train[df_train.label<=1]\n",
    "df_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>most_similar_paragraph</th>\n",
       "      <th>harvest_date</th>\n",
       "      <th>url</th>\n",
       "      <th>most_similar_par_cos</th>\n",
       "      <th>claim</th>\n",
       "      <th>text_embedding_claim</th>\n",
       "      <th>label</th>\n",
       "      <th>text_embedding_par</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Στην εντατική ο υπουργός Άμυνας των ΗΠΑ, Lloyd...</td>\n",
       "      <td>Το Παρασκήνιο της Αγοράς Αφιέρωμα : 26 πολιτικ...</td>\n",
       "      <td>ο υπουργός Άμυνας των ΗΠΑ, Lloyd Austin</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>https://www.bankingnews.gr/diethni/articles/72...</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>Ο Υπουργός Άμυνας των ΗΠΑ, Lloyd Austin, φέρετ...</td>\n",
       "      <td>[-0.005461568478494883, -0.007872236892580986,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.04415225610136986, -0.00244485423900187, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id                                              title  \\\n",
       "0       0.0  Στην εντατική ο υπουργός Άμυνας των ΗΠΑ, Lloyd...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Το Παρασκήνιο της Αγοράς Αφιέρωμα : 26 πολιτικ...   \n",
       "\n",
       "                    most_similar_paragraph harvest_date  \\\n",
       "0  ο υπουργός Άμυνας των ΗΠΑ, Lloyd Austin   2024-02-23   \n",
       "\n",
       "                                                 url  most_similar_par_cos  \\\n",
       "0  https://www.bankingnews.gr/diethni/articles/72...                0.6614   \n",
       "\n",
       "                                               claim  \\\n",
       "0  Ο Υπουργός Άμυνας των ΗΠΑ, Lloyd Austin, φέρετ...   \n",
       "\n",
       "                                text_embedding_claim  label  \\\n",
       "0  [-0.005461568478494883, -0.007872236892580986,...      0   \n",
       "\n",
       "                                  text_embedding_par  \n",
       "0  [-0.04415225610136986, -0.00244485423900187, -...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create the list for the holding the training vectors (claim plus n*paragraphs)\n",
    "combined_array = list()\n",
    "#create a list holding the classification label\n",
    "label = list()\n",
    "#for each unique claim id \n",
    "for i in df_train.claim_id.unique():\n",
    "    #create a temp df holding information about a specific claim_id\n",
    "    df = df_train[df_train.claim_id==i]\n",
    "    try:\n",
    "        # display(df)\n",
    "        #store the claim embedding\n",
    "        claim=np.array(df.iloc[0,8])\n",
    "        #store the label\n",
    "        label.append(df.iloc[0,9])\n",
    "    except IndexError:\n",
    "        continue\n",
    "    # for each paragraph related to the claim\n",
    "    par = []\n",
    "    for j in range(len(df)):\n",
    "        #concatenate all the paragraphs together\n",
    "        par = np.concatenate([par,df.iloc[j,10]])\n",
    "    #finally concatenate the related paragraphs with the claim\n",
    "    claim = np.concatenate([claim, par])\n",
    "    #store the final vector on an array\n",
    "    combined_array.append(claim)\n",
    "    \n",
    "\n",
    "#we rearrange the combined array into an array format\n",
    "arr = [combined_array[i] for i in range(len(combined_array))]\n",
    "\n",
    "#make the train test split based on the previous arrays\n",
    "X_train, X_test, y_train, y_test= train_test_split(arr  ,np.array(label).astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "#PCA feature reduction (optional)\n",
    "\n",
    "# X_train_scaled, X_test_scaled = list(),list()\n",
    "\n",
    "# for x_train in X_train:\n",
    "#     x_train = np.array(x_train, dtype=np.float64)\n",
    "#     x_train = x_train.reshape(1536, 3) # the format is transformed into a 1536shaped vector. The second number in a tuple is equal to \n",
    "#     pca = PCA(n_components = 1)        # the number of extra paragraphs plus one. In this example we have 2 extra pars plus one\n",
    "#     X_train_scaled.append(pca.fit_transform(x_train))\n",
    "    \n",
    "# for x_test in X_test:\n",
    "#     x_test = np.array(x_test, dtype=np.float64)\n",
    "#     x_test = x_test.reshape(1536, 2)\n",
    "#     pca = PCA(n_components = 1) \n",
    "#     X_test_scaled.append(pca.fit_transform(x_test))\n",
    "\n",
    "#default classification\n",
    "MLP(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "#classification using the pca technique\n",
    "#MLP(np.array(X_train_scaled).squeeze(), np.array(X_test_scaled).squeeze(), y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
